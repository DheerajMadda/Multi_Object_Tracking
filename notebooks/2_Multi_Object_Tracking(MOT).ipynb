{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3989c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be run only once per session\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors import YoloV8\n",
    "from utils import YamlParser, TrackingRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79df877",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device, type(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56593bec",
   "metadata": {},
   "source": [
    "## 1. Initialize object detector (YoloV8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YoloV8(\n",
    "    weights=\"yolov8n.pt\",\n",
    "    conf_thres=0.45,\n",
    "    display_labels=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a0514",
   "metadata": {},
   "source": [
    "### 1.1. (Optional) Only detect specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e76fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### view class mapping\n",
    "detector.class_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Only execute below line if want to detect only specific classes\n",
    "\n",
    "# e.g. detect only bicycles and cars\n",
    "detector.detect_classes(classes=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af6be2",
   "metadata": {},
   "source": [
    "### 1.2. (Optional) Only detect in specific zone/ region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63470e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Only execute below lines if want to detect only in specific zones\n",
    "\n",
    "# define polygon zones (from start_pixel_location to end_pixel_location)\n",
    "zone1 = [\n",
    "    [145, 120],\n",
    "    [10,  295],\n",
    "    [360, 295],\n",
    "    [348, 203],\n",
    "    [320, 120]\n",
    "]\n",
    "\n",
    "zone2 = [\n",
    "    [506, 200],\n",
    "    [462, 238],\n",
    "    [390, 340],\n",
    "    [542, 340],\n",
    "    [588, 238],\n",
    "    [618, 200]\n",
    "]\n",
    "\n",
    "zones = [zone1, zone2]\n",
    "\n",
    "detector.detect_zones(\n",
    "    zones=zones,\n",
    "    frame_resolution_wh=(640, 360),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808002cb",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3d918",
   "metadata": {},
   "source": [
    "## 2. Initialize tracker\n",
    "#### ------------------------------------------\n",
    "\n",
    "- There are various types of Trackers for performing Multi Object Tracking (MOT).\n",
    "- SORT - Simple Online & Realtime Tracking (2 Feb 2016; (https://arxiv.org/abs/1602.00763) was a breakthrough in the field of trackers in the year 2016. It gained a lot of attention and eventually many other trackers are implemented based on its foundation.\n",
    "- Then came the DeepSORT (21 Mar 2017) build on top of SORT which uses deep learning for target associations and is widely used even today.\n",
    "- Thus, there are many trackers that are implemented till now and currently, the new **State-of-the-Art** (SOTA) trackers are **OC-SORT, ByteTrack, BotSORT, StrongSORT, Deep OC-SORT, ** which are released in the year **2022-2023**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc30a77",
   "metadata": {},
   "source": [
    "### Creating a custom feature extraction model for ReIDentification task\n",
    "\n",
    "- ReID model is used for extracting the features of the object (detected by object detectors like Yolov8)\n",
    "- DeepSORT, BoTSORT, StrongSORT and DeepOCSORT.\n",
    "- These trackers use the ReID model. Hence, these are deep learning based MOT trackers and are used when performing inference on GPUs.\n",
    "- These trackers are normally not used for CPU inferencing.\n",
    "\n",
    "- You can train a resnet18 or resnet50 model on a custom dataset and can provide the model weight path to the respective tracking class (you can find this in later cells of this notebook for the above mentioned trackers)\n",
    "\n",
    "#### -----------------------------\n",
    "- Please note, the dataset you are supposed to train the ReID model should contain only the objects in it. i.e. the images should be cropped so that the cropped images only contain the object.\n",
    "- Create a dataset of such cropped images for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe57807",
   "metadata": {},
   "source": [
    "### 2.1. SORT [2 Feb 2016]\n",
    "#### Simple Online and Realtime Tracking\n",
    "#### https://arxiv.org/abs/1602.00763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import SORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"sort\", \"configs\", \"sort.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = SORT(\n",
    "    max_age=cfg.sort.max_age,\n",
    "    min_hits=cfg.sort.min_hits,\n",
    "    iou_threshold=cfg.sort.iou_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7241237c",
   "metadata": {},
   "source": [
    "### 2.2. DeepSORT [21 Mar 2017]\n",
    "#### Simple Online and Realtime Tracking with a Deep Association Metric\n",
    "#### https://arxiv.org/abs/1703.07402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e283fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_weights = os.path.join(os.getcwd(), \"trackers\", \"deepsort\", \"deep\", \"checkpoint\", \"osnet_x0_25_msmt17.pt\")\n",
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"deepsort\", \"configs\", \"deepsort.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = DeepSORT(\n",
    "    model_weights=reid_weights,\n",
    "    device=device,\n",
    "    fp16=True,\n",
    "    max_dist=cfg.deepsort.max_dist, \n",
    "    min_confidence=cfg.deepsort.min_confidence, \n",
    "    nms_max_overlap=cfg.deepsort.nms_max_overlap, \n",
    "    max_iou_distance=cfg.deepsort.max_iou_distance, \n",
    "    max_age=cfg.deepsort.max_age, \n",
    "    n_init=cfg.deepsort.n_init, \n",
    "    nn_budget=cfg.deepsort.nn_budget\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6cdf366",
   "metadata": {},
   "source": [
    "### 2.3. StrongSORT [28 Feb 2022]\n",
    "#### Make DeepSORT Great Again  (Catchy Slogan! It is based on a popular tracker: DeepSORT)\n",
    "#### https://arxiv.org/abs/2202.13514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import StrongSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_weights = os.path.join(os.getcwd(), \"trackers\", \"strongsort\", \"deep\", \"checkpoint\", \"osnet_x0_25_msmt17.pt\")\n",
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"strongsort\", \"configs\", \"strongsort.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = StrongSORT(\n",
    "    model_weights=reid_weights,\n",
    "    device=device,\n",
    "    fp16=True,\n",
    "    max_dist=cfg.strongsort.max_dist,\n",
    "    max_iou_dist=cfg.strongsort.max_iou_dist,\n",
    "    max_age=cfg.strongsort.max_age,\n",
    "    max_unmatched_preds=cfg.strongsort.max_unmatched_preds,\n",
    "    n_init=cfg.strongsort.n_init,\n",
    "    nn_budget=cfg.strongsort.nn_budget,\n",
    "    mc_lambda=cfg.strongsort.mc_lambda,\n",
    "    ema_alpha=cfg.strongsort.ema_alpha \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591ec74",
   "metadata": {},
   "source": [
    "### 2.4. OC-SORT [27 Mar 2022]\n",
    "#### Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking\n",
    "#### https://arxiv.org/abs/2203.14360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import OCSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d84a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"ocsort\", \"configs\", \"ocsort.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = OCSORT(\n",
    "    det_thresh=cfg.ocsort.det_thresh,\n",
    "    max_age=cfg.ocsort.max_age,\n",
    "    min_hits=cfg.ocsort.min_hits,\n",
    "    iou_threshold=cfg.ocsort.iou_thresh,\n",
    "    delta_t=cfg.ocsort.delta_t,\n",
    "    asso_func=cfg.ocsort.asso_func,\n",
    "    inertia=cfg.ocsort.inertia,\n",
    "    use_byte=cfg.ocsort.use_byte,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746e4bc",
   "metadata": {},
   "source": [
    "### 2.5. ByteTrack [7 Apr 2022]\n",
    "#### Multi-Object Tracking by Associating Every Detection Box\n",
    "#### https://paperswithcode.com/paper/bytetrack-multi-object-tracking-by-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import BYTETrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"bytetrack\", \"configs\", \"bytetrack.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = BYTETrack(\n",
    "    track_thresh=cfg.bytetrack.track_thresh,\n",
    "    match_thresh=cfg.bytetrack.match_thresh,\n",
    "    track_buffer=cfg.bytetrack.track_buffer,\n",
    "    frame_rate=cfg.bytetrack.frame_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a0310",
   "metadata": {},
   "source": [
    "### 2.6. BotSORT [7 Jul 2022]\n",
    "#### Robust Associations Multi-Pedestrian Tracking\n",
    "#### https://paperswithcode.com/paper/bot-sort-robust-associations-multi-pedestrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import BoTSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_weights = os.path.join(os.getcwd(), \"trackers\", \"botsort\", \"deep\", \"checkpoint\", \"osnet_x0_25_msmt17.pt\")\n",
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"botsort\", \"configs\", \"botsort.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = BoTSORT(\n",
    "    model_weights=reid_weights,\n",
    "    device=device,\n",
    "    fp16=True,\n",
    "    track_high_thresh=cfg.botsort.track_high_thresh,\n",
    "    new_track_thresh=cfg.botsort.new_track_thresh,\n",
    "    track_buffer=cfg.botsort.track_buffer,\n",
    "    match_thresh=cfg.botsort.match_thresh,\n",
    "    proximity_thresh=cfg.botsort.proximity_thresh,\n",
    "    appearance_thresh=cfg.botsort.appearance_thresh,\n",
    "    cmc_method=cfg.botsort.cmc_method,\n",
    "    frame_rate=cfg.botsort.frame_rate,\n",
    "    lambda_=cfg.botsort.lambda_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd6554",
   "metadata": {},
   "source": [
    "### 2.7. Deep OC-SORT [23 Feb 2023]\n",
    "#### Deep OC-SORT: Multi-Pedestrian Tracking by Adaptive Re-Identification (DeepSORT + OCSORT)\n",
    "#### https://arxiv.org/abs/2302.11813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers import DeepOCSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_weights = os.path.join(os.getcwd(), \"trackers\", \"deepocsort\", \"deep\", \"checkpoint\", \"osnet_x0_25_msmt17.pt\")\n",
    "tracker_config = os.path.join(os.getcwd(), \"trackers\", \"deepocsort\", \"configs\", \"deepocsort.yaml\")\n",
    "\n",
    "cfg = YamlParser()\n",
    "cfg.merge_from_file(tracker_config)\n",
    "\n",
    "tracker = DeepOCSORT(\n",
    "    model_weights=reid_weights,\n",
    "    device=device,\n",
    "    fp16=True,\n",
    "    det_thresh=cfg.deepocsort.det_thresh,\n",
    "    max_age=cfg.deepocsort.max_age,\n",
    "    min_hits=cfg.deepocsort.min_hits,\n",
    "    iou_threshold=cfg.deepocsort.iou_thresh,\n",
    "    delta_t=cfg.deepocsort.delta_t,\n",
    "    asso_func=cfg.deepocsort.asso_func,\n",
    "    inertia=cfg.deepocsort.inertia,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2191ec",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ab0c8",
   "metadata": {},
   "source": [
    "## 3. Run Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_runner = TrackingRunner(detector, tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cd921",
   "metadata": {},
   "source": [
    "tracking_runner.run( </br>\n",
    "&emsp;source=source, &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; # 0 for webcam; otherwise path to image/video/directory </br>\n",
    "&emsp;output=output, &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; # optional; default_value=None. A output path to save an image or a video </br>\n",
    "&emsp;display=False, &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; # optional; default_value = False. Displays output in a window </br>\n",
    "&emsp;keyboard_interrupt_key=\"q\" &emsp; # optional; default_value = \"q\". A keyboard button to stop/quit running detection </br>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da117f",
   "metadata": {},
   "source": [
    "### 3.1. Run on sequence of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5728b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = os.path.join(os.getcwd(), \"data\", \"inputs\", \"sample_sequence\")\n",
    "save_output = os.path.join(os.getcwd(), \"data\", \"outputs\", \"tracking\", \"track_output_sequence.avi\")\n",
    "tracking_runner.run(source, save_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07719d4",
   "metadata": {},
   "source": [
    "### 3.2. Run on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = os.path.join(os.getcwd(), \"data\", \"inputs\", \"sample_video.mp4\")\n",
    "save_output = os.path.join(os.getcwd(), \"data\", \"outputs\", \"tracking\", \"track_output_video.avi\")\n",
    "tracking_runner.run(source, save_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d94155",
   "metadata": {},
   "source": [
    "### 3.3. Run on webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c106e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = 0\n",
    "# save_output = os.path.join(os.getcwd(), \"data\", \"outputs\", \"tracking\", \"track_output_webcam.avi\")\n",
    "\n",
    "# tracking_runner.run(source, save_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
